{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>keywords</th>\n",
       "      <th>top_kb_index</th>\n",
       "      <th>second_kb_index</th>\n",
       "      <th>third_kb_index</th>\n",
       "      <th>emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ноутбук во временное пользование</td>\n",
       "      <td>Ноутбук</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Доступ к сетевым папкам</td>\n",
       "      <td>Сетевые папки, сетевая папка, сетевой диск</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Поддержка рабочих мест, настройка удаленки</td>\n",
       "      <td>Компьютер, ПК, сканер, принтер, МФУ, телефон, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ИС УОП, 1С:БГУ 2.0, 1С:ЗКГУ 3.0, 1С:ФПЗ</td>\n",
       "      <td>1С, БГУ, ФПЗ, УОП, ЗКГУ, ЗКБУ, Сервер, удаленн...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1С: Документооборот</td>\n",
       "      <td>1С, Документооборот, ДО</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name  \\\n",
       "0            Ноутбук во временное пользование   \n",
       "1                     Доступ к сетевым папкам   \n",
       "2  Поддержка рабочих мест, настройка удаленки   \n",
       "3     ИС УОП, 1С:БГУ 2.0, 1С:ЗКГУ 3.0, 1С:ФПЗ   \n",
       "4                         1С: Документооборот   \n",
       "\n",
       "                                            keywords  top_kb_index  \\\n",
       "0                                            Ноутбук           NaN   \n",
       "1         Сетевые папки, сетевая папка, сетевой диск           NaN   \n",
       "2  Компьютер, ПК, сканер, принтер, МФУ, телефон, ...           NaN   \n",
       "3  1С, БГУ, ФПЗ, УОП, ЗКГУ, ЗКБУ, Сервер, удаленн...           NaN   \n",
       "4                            1С, Документооборот, ДО           NaN   \n",
       "\n",
       "   second_kb_index  third_kb_index emoji  \n",
       "0              NaN             NaN   NaN  \n",
       "1              NaN             NaN   NaN  \n",
       "2              NaN             NaN   NaN  \n",
       "3              NaN             NaN   NaN  \n",
       "4              NaN             NaN   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/12.xlsx', na_values='None')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(r'C:\\Users\\maxxx\\VSprojects\\bots\\MIPT\\backend\\data')\n",
    "top_kb_file = data_path / Path('kb_top_level.csv')\n",
    "second_kb_file = data_path / Path('kb_second_level_oldmipt.csv')\n",
    "third_kb_file = data_path / Path('kb_third_level_oldmipt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df = pd.read_csv(top_kb_file, sep=';', na_values='None')\n",
    "second_df = pd.read_csv(second_kb_file, sep=';', na_values='None')\n",
    "third_df = pd.read_csv(third_kb_file, sep=';', na_values='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def f(row):\n",
    "#     #print(row['name'])\n",
    "#     print(row)\n",
    "\n",
    "# df.apply(f);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>keywords</th>\n",
       "      <th>top_kb_index</th>\n",
       "      <th>second_kb_index</th>\n",
       "      <th>third_kb_index</th>\n",
       "      <th>emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, keywords, top_kb_index, second_kb_index, third_kb_index, emoji]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    if row['name'] in top_df['name'].values:\n",
    "        row['top_kb_index'] = top_df[top_df['name'] == row['name']]['top_kb_index'].values[0]\n",
    "        row['emoji'] = top_df[top_df['name'] == row['name']]['emoji'].values[0]\n",
    "        df.loc[idx] = row\n",
    "    elif row['name'] in second_df['name'].values:\n",
    "        row['top_kb_index'] = second_df[second_df['name'] == row['name']]['top_kb_index'].values[0]\n",
    "        row['second_kb_index'] = second_df[second_df['name'] == row['name']]['second_kb_index'].values[0]\n",
    "        row['emoji'] = second_df[second_df['name'] == row['name']]['emoji'].values[0]\n",
    "        df.loc[idx] = row\n",
    "    elif row['name'] in third_df['name'].values:\n",
    "        row['top_kb_index'] = third_df[third_df['name'] == row['name']]['top_kb_index'].values[0]\n",
    "        row['second_kb_index'] = third_df[third_df['name'] == row['name']]['second_kb_index'].values[0]\n",
    "        row['third_kb_index'] = third_df[third_df['name'] == row['name']]['third_kb_index'].values[0]\n",
    "        row['emoji'] = third_df[third_df['name'] == row['name']]['emoji'].values[0]\n",
    "        df.loc[idx] = row\n",
    "    else:\n",
    "        # print(f'error string = {idx}; {row[\"name\"]}')\n",
    "        ...\n",
    "\n",
    "df[df['emoji'] == None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['emoji'] == None]\n",
    "df.to_excel('../data/keywords.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                0\n",
       "keywords            0\n",
       "top_kb_index        0\n",
       "second_kb_index     0\n",
       "third_kb_index     38\n",
       "emoji               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/keywords.xlsx')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proccess_kw(words: str):\n",
    "    words = words.lower()\n",
    "    words = words.replace(';', '')\n",
    "    words = words.replace(',', '')\n",
    "    words = words.replace('.', '')\n",
    "    words = words.replace('-', ' ')\n",
    "\n",
    "    words_arr = [word for word in words.split(' ') if len(word) > 1]\n",
    "\n",
    "    return words_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for el in df['keywords'].apply(proccess_kw):\n",
    "#     print(el)\n",
    "df['keywords'] = df['keywords'].apply(proccess_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_word = 'почта'\n",
    "\n",
    "# df[pd.isin]\n",
    "# df[df['keywords'].isin([my_word])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maxxx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "patterns = \"[A-Za-z0-9!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\-]+\"\n",
    "stopwords_ru = stopwords.words(\"russian\")\n",
    "morph = MorphAnalyzer()\n",
    "def lemmatize(doc):\n",
    "    doc = re.sub(patterns, ' ', doc)\n",
    "    print(f'doc  = {doc}')\n",
    "    tokens = []\n",
    "    for token in doc.split():\n",
    "        print(f'token = {token}')\n",
    "        if token and token not in stopwords_ru:\n",
    "            token = token.strip()\n",
    "            token = morph.normal_forms(token)[0]\n",
    "            \n",
    "            tokens.append(token)\n",
    "    # print(tokens)\n",
    "    if len(tokens) > 0:\n",
    "        return tokens\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc  = ошибку\n",
      "token = ошибку\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ошибка']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize('ошибку')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m request \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mмои документы\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n",
      "Cell \u001b[1;32mIn[109], line 11\u001b[0m, in \u001b[0;36mlemmatize\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(doc):\n\u001b[1;32m---> 11\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msplit():\n",
      "File \u001b[1;32mc:\\Users\\maxxx\\AppData\\Local\\Programs\\Python\\Python310\\lib\\re.py:209\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    203\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "request = ['мои документы']\n",
    "res = lemmatize(request)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "\n",
    "def get_kw2idx(df: pd.DataFrame) -> dict[set]:\n",
    "    kw2idx = defaultdict(set)\n",
    "    for idx, row in df.iterrows():\n",
    "        for word in row['keywords']:\n",
    "            kw2idx[word].add(idx)\n",
    "\n",
    "        # print(row['keywords'])\n",
    "        # print(lemmatize(' '.join(row['keywords'])))\n",
    "\n",
    "        lemmatize_keywords = lemmatize(' '.join(row['keywords']))\n",
    "        for word in lemmatize_keywords if lemmatize_keywords is not None else []:\n",
    "            kw2idx[word].add(idx)\n",
    "            ...\n",
    "\n",
    "    return kw2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw2idx = get_kw2idx(df)\n",
    "kw2idx.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_word = 'документы'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корп. аккаунт: получить и восстановить\n",
      "Изменить пароль от корп. сервисов\n",
      "Корп. аккаунт @mipt.ru для сотрудников базовых кафедр, дистанционных работников\n",
      "Получение почты @mipt.ru для подразделения и мероприятия \n",
      "Получение @phystech.edu студентами, аспирантами, выпускниками\n",
      "Получение @phystech.edu сотрудниками\n",
      "Получение @phystech.edu для подразделения и мероприятия\n",
      "Восстановление пароля от @phystech.edu \n"
     ]
    }
   ],
   "source": [
    "for idx in kw2idx[my_word]:\n",
    "    print(df.loc[idx, 'name'])\n",
    "    # print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'code': 1,\n",
       "  'pos': 0,\n",
       "  'row': 0,\n",
       "  'col': 0,\n",
       "  'len': 6,\n",
       "  'word': 'ошипка',\n",
       "  's': ['ошибка']},\n",
       " {'code': 1,\n",
       "  'pos': 9,\n",
       "  'row': 0,\n",
       "  'col': 9,\n",
       "  'len': 5,\n",
       "  'word': 'текве',\n",
       "  's': ['тыкве', 'тексе', 'тейкове', 'тикве']}]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = 'http://speller.yandex.net/services/spellservice.json/checkText'\n",
    "\n",
    "response = requests.post(\n",
    "    URL,\n",
    "    data={\n",
    "        'text': 'ошипка в текве',\n",
    "        'lang': 'ru, en',\n",
    "        'format': 'plain'\n",
    "    }\n",
    ")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f'{URL}?text=какойв-то течст с ошипками точно&lang=ru&format=plain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'code': 1,\n",
       "  'pos': 0,\n",
       "  'row': 0,\n",
       "  'col': 0,\n",
       "  'len': 6,\n",
       "  'word': 'какойв',\n",
       "  's': ['какой']},\n",
       " {'code': 1,\n",
       "  'pos': 10,\n",
       "  'row': 0,\n",
       "  'col': 10,\n",
       "  'len': 5,\n",
       "  'word': 'течст',\n",
       "  's': ['текст', 'тест']},\n",
       " {'code': 1,\n",
       "  'pos': 18,\n",
       "  'row': 0,\n",
       "  'col': 18,\n",
       "  'len': 8,\n",
       "  'word': 'ошипками',\n",
       "  's': ['ошибками', 'ошипками']}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['мой', 'документ', 'почнм', 'тектс']\n"
     ]
    }
   ],
   "source": [
    "request = 'мои документы почнму и 23 какой-то тектс'\n",
    "res = lemmatize(request)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "res = lemmatize(\"fff что здесб такое?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['мои', 'документы']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
